# Location and scale mixture of AR model

## Earthquakes data

```{r}
#| label: fig-earthquakes-time-series
#| fig-cap: Time series of observed earthquakes.

earthquakes.dat <- read.delim("./data/earthquakes.txt")
earthquakes.dat$Quakes = as.numeric(earthquakes.dat$Quakes)

y.dat=earthquakes.dat$Quakes[1:100] ## this is the training data
y.new=earthquakes.dat$Quakes[101:103] ## this is the test data

plot.ts(
  y.dat,
  ylab = expression(italic(y)[italic(t)]),
  xlab = expression(italic(t)),
  main = ""
)
```

## Setting the prior

We will fit a two-component AR(3) mixture. That is, $p = 3$ and $K = 2$. Firstly, we set up the model by choosing prior hyperparameters. We use weakly informative priors for all parameters. That is, we set $a_{1} = a_{2} = 1$, $\mathbf{m}_{0} = \left(0, 0, 0\right)^{\top}$, $\mathbf{C}_{0} = 10\ \mathbf{I}_{3}$, and $n_{0} = d_{0} = 0.02$. They are specified using the following code:

```{r}
library(MCMCpack)
library(mvtnorm)

p = 3  # order of AR process
K = 2  # number of components

Y = matrix(y.dat[(p+1):length(y.dat)], ncol = 1)  # y_{p+1:T}
Fmtx = matrix(
  c(
    y.dat[3:(length(y.dat)-1)],
    y.dat[2:(length(y.dat)-2)],
    y.dat[1:(length(y.dat)-3)]
  ),
  nrow = 3, 
  byrow = TRUE
)  # design matrix F
n = length(Y)  # T - p

## Prior hyperparameters
m0 = matrix(rep(0, p), ncol = 1)
C0 = 10 * diag(p)
C0.inv = (1 / 10) * diag(p)
n0 = 2
d0 = 2
a = rep(1, K)
```

## Sampling functions

Now we define the sampling function for all the parameters, using the posterior full conditional distribution we have derived.

```{r}
sample_omega=function(L.cur){
  n.vec=sapply(1:K, function(k){sum(L.cur==k)})
  rdirichlet(1,a+n.vec)
}

sample_L_one=function(beta.cur,omega.cur,nu.cur,y.cur,Fmtx.cur){
  log_prob_k = function(k) {
    beta.use = beta.cur[((k-1)*p + 1):(k*p)]
    log(omega.cur[k]) +
      dnorm(y.cur, mean = sum(beta.use * Fmtx.cur), sd = sqrt(nu.cur[k]), log = TRUE)
  }
  log_probs.vec = sapply(1:K, log_prob_k)
  log_probs.vec = log_probs.vec - max(log_probs.vec)
  probs.vec = exp(log_probs.vec)
  L.sample = sample(1:K, 1, prob = probs.vec / sum(probs.vec))
  # prob_k=function(k){
  #   beta.use=beta.cur[((k-1)*p+1):(k*p)]
  #   omega.cur[k]*dnorm(y.cur,mean=sum(beta.use*Fmtx.cur),sd=sqrt(nu.cur[k]))
  # }
  # prob.vec=sapply(1:K, prob_k)
  # L.sample=sample(1:K,1,prob=prob.vec/sum(prob.vec))
  return(L.sample)
}

sample_L=function(y,x,beta.cur,omega.cur,nu.cur){
  L.new=sapply(1:n, function(j){sample_L_one(beta.cur,omega.cur,nu.cur,y.cur=y[j,],Fmtx.cur=x[,j])})
  return(L.new)
}

sample_nu=function(k,L.cur){
  idx.select=(L.cur==k)
  n.k=sum(idx.select)
  if(n.k==0){
    d.k.star=d0
    n.k.star=n0
  }else{
    y.tilde.k=Y[idx.select,]
    Fmtx.tilde.k=Fmtx[,idx.select]
    e.k=y.tilde.k-t(Fmtx.tilde.k)%*%m0
    Q.k=t(Fmtx.tilde.k)%*%C0%*%Fmtx.tilde.k+diag(n.k)
    Q.k.inv=chol2inv(chol(Q.k))
    d.k.star=d0+t(e.k)%*%Q.k.inv%*%e.k
    n.k.star=n0+n.k
  }
  
  1/rgamma(1,shape=n.k.star/2,rate=d.k.star/2)
}

sample_beta=function(k,L.cur,nu.cur){
  nu.use=nu.cur[k]
  idx.select=(L.cur==k)
  n.k=sum(idx.select)
  if(n.k==0){
    m.k=m0
    C.k=C0
  }else{
    y.tilde.k=Y[idx.select,]
    Fmtx.tilde.k=Fmtx[,idx.select]
    e.k=y.tilde.k-t(Fmtx.tilde.k)%*%m0
    Q.k=t(Fmtx.tilde.k)%*%C0%*%Fmtx.tilde.k+diag(n.k)
    Q.k.inv=chol2inv(chol(Q.k))
    A.k=C0%*%Fmtx.tilde.k%*%Q.k.inv
    m.k=m0+A.k%*%e.k
    C.k=C0-A.k%*%Q.k%*%t(A.k)
  }
  
  rmvnorm(1,m.k,nu.use*C.k)
}
```

## Initial values
```{r}
## Set initial values
beta.cur = rep(0, p * K)
L.cur = rep(1, n)
omega.cur = rep(1 / K, K)
nu.cur = rep(1, K)

## Define placeholders to track values over time
nsim = 10e3
beta.mtx = matrix(0, nrow = p * K, ncol = nsim)
L.mtx = matrix(0, nrow = n, ncol = nsim)
omega.mtx = matrix(0, nrow = K, ncol = nsim)
nu.mtx = matrix(0, nrow = K, ncol = nsim)
```

## Sampler

```{r}
## Gibbs sampler
set.seed(123)
for (i in 1:nsim) {
  
  ## Sample omega
  omega.cur = sample_omega(L.cur)
  omega.mtx[, i]  = omega.cur
  
  ## Sample L
  L.cur = sample_L(Y, Fmtx, beta.cur, omega.cur, nu.cur)
  L.mtx[, i] = L.cur
  
  ## Sample nu
  nu.cur = sapply(1:K, function(k){sample_nu(k, L.cur)})
  nu.mtx[, i] = nu.cur
  
  ## Sample beta
  beta.cur = as.vector(sapply(1:K, function(k){sample_beta(k, L.cur, nu.cur)}))
  beta.mtx[, i] = beta.cur
  
  ## Show iteration
  if (i %% 1000 == 0) {
    print(paste("Number of iterations:", i))
  }
}
```

## Posterior check

```{r}
sample.select.idx = seq(5001, 10000, by = 1)

post.pred.y.mix = function(idx) {
  
  k.vec.use = L.mtx[, idx]
  beta.use = beta.mtx[, idx]
  nu.use = nu.mtx[, idx]
  
  get.mean = function(s) {
    k.use = k.vec.use[s]
    sum(Fmtx[, s] * beta.use[((k.use - 1) * p + 1): (k.use * p)])
  }
  get.sd = function(s) {
    k.use = k.vec.use[s]
    sqrt(nu.use[k.use])
  }
  
  mu.y = sapply(1:n, get.mean)
  sd.y = sapply(1:n, get.sd)
  sapply(1:length(mu.y), function(k){rnorm(1, mu.y[k], sd.y[k])})
}

y.post.pred.sample = sapply(sample.select.idx, post.pred.y.mix)

summary.vec95 = function(vec) {
  c(unname(quantile(vec, 0.025)), mean(vec), unname(quantile(vec, 0.975)))
}

summary.y = apply(y.post.pred.sample, 1, summary.vec95)

plot(Y, type='b', xlab='Time', ylab='', pch=16)
lines(summary.y[2,], type='b', col='grey', lty=2, pch=4)
lines(summary.y[1,], type='l', col='purple', lty=3)
lines(summary.y[3,], type='l', col='purple', lty=3)
legend(
  "topright",
  legend=c('Truth','Mean','95% C.I.'),
  lty=1:3,
  col=c('black','grey','purple'),horiz = T,pch=c(16,4,NA)
)
```

